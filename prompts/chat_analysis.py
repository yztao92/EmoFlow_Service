# chat_analysis.py
import logging
import json
from typing import Dict, Any
from llm.llm_factory import chat_with_llm
import re

ANALYZE_PROMPT = """
ä½ æ˜¯å¯¹è¯åˆ†æå™¨ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·ä¸AIçš„å¯¹è¯çŠ¶æ€ã€‚è¯·ä»”ç»†é˜…è¯»æ•´ä¸ªå¯¹è¯å†å²ï¼Œå‡†ç¡®åˆ¤æ–­å½“å‰çŠ¶æ€ã€‚

## åˆ†ææ­¥éª¤
1. é¦–å…ˆé€šè¯»æ•´ä¸ªå¯¹è¯å†å²ï¼Œç†è§£ç”¨æˆ·æƒ…ç»ªå‘å±•è½¨è¿¹
2. é‡ç‚¹å…³æ³¨ç”¨æˆ·çš„æœ€æ–°è¡¨è¾¾å’Œæ•´ä½“æƒ…ç»ªå€¾å‘  
3. åˆ†æAIå›å¤çš„æ¨¡å¼å’Œç‰¹ç‚¹
4. åŸºäºä»¥ä¸Šåˆ†æåšå‡ºå‡†ç¡®åˆ¤æ–­

## å¯¹è¯å†å²ï¼š
{state_summary}

## å½“å‰ç”¨æˆ·è¾“å…¥ï¼š
{question}

## å·²æœç´¢å†…å®¹ï¼š
{searched_content}

## åˆ¤æ–­ç»´åº¦å’Œæ ‡å‡†ï¼š

### 1. emotion_typeï¼ˆå¿…é€‰å…¶ä¸€ï¼‰ï¼š
åˆ†æç”¨æˆ·åœ¨æ•´ä¸ªå¯¹è¯ä¸­è¡¨ç°å‡ºçš„**ä¸»è¦æƒ…ç»ªå€¾å‘**ï¼š
- "tired"ï¼šè¡¨è¾¾ç–²æƒ«ã€å€¦æ€ ã€è™šæ— ã€æ²¡åŠ›æ°”
- "negative"ï¼šè¡¨è¾¾æ‚²ä¼¤ã€ç„¦è™‘ã€ç—›è‹¦ã€å¤±è½ã€éš¾è¿‡
- "angry"ï¼šè¡¨è¾¾æ„¤æ€’ã€å§”å±ˆã€ä¸æ»¡ã€è¢«å†’çŠ¯
- "positive"ï¼šè¡¨è¾¾å¼€å¿ƒã€æ¿€åŠ¨ã€æ»¡è¶³ã€å…´å¥‹
- "neutral"ï¼šæƒ…ç»ªä¸æ˜æ˜¾æˆ–çœŸæ­£çš„ä¸­æ€§è¡¨è¾¾


### 2. user_has_shared_reasonï¼ˆboolï¼‰ï¼š
ç”¨æˆ·æ˜¯å¦å·²ç»è¯´å‡ºäº†**å…·ä½“çš„æƒ…ç»ªåŸå› æˆ–äº‹ä»¶**ï¼Ÿ

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šç”¨æˆ·è¯´å‡ºäº†å…·ä½“çš„äººã€äº‹ã€ç‰©ã€æ—¶é—´ã€åœ°ç‚¹ã€äº‹ä»¶ç­‰å…·ä½“ä¿¡æ¯
- Falseï¼šç”¨æˆ·åªè¡¨è¾¾äº†æƒ…ç»ªçŠ¶æ€ï¼Œæ²¡æœ‰å…·ä½“å†…å®¹"

**å…³é”®åˆ¤æ–­ç‚¹**ï¼šçœ‹æ˜¯å¦åŒ…å«å…·ä½“çš„äººåã€äº‹ä»¶ã€æ—¶é—´ã€åœ°ç‚¹ã€å¯¹è±¡ç­‰å…·ä½“ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»…ä»…æè¿°æƒ…ç»ªçŠ¶æ€

### 3. ai_has_given_suggestionï¼ˆboolï¼‰ï¼š
AIæ˜¯å¦å·²ç»æå‡ºè¿‡**å…·ä½“çš„å»ºè®®æˆ–è¡ŒåŠ¨æ–¹æ¡ˆ**ï¼Ÿ

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šAIç»™å‡ºäº†å…·ä½“çš„è¡ŒåŠ¨å»ºè®®ã€è§£å†³æ–¹æ¡ˆæˆ–æ“ä½œæŒ‡å¯¼
- Falseï¼šAIåªæ˜¯è¯¢é—®ã€å…±æƒ…ã€å€¾å¬ï¼Œæ²¡æœ‰ç»™å‡ºè¡ŒåŠ¨å»ºè®®


### 4. consecutive_ai_questionsï¼ˆboolï¼‰ï¼š
æ£€æŸ¥AIçš„**æœ€è¿‘è¿ç»­ä¸‰è½®å›å¤**æ˜¯å¦éƒ½ä»¥é—®å¥ç»“å°¾ï¼š

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šAIæœ€è¿‘è¿ç»­ä¸‰è½®å›å¤éƒ½ä»¥é—®å¥ç»“å°¾ï¼ˆå¦‚"å—ï¼Ÿ"ã€"å‘¢ï¼Ÿ"ã€"ä»€ä¹ˆï¼Ÿ"ç­‰ï¼‰
- Falseï¼šAIå›å¤å°‘äºä¸‰è½®ï¼Œæˆ–è€…ä¸‰è½®ä¸­æœ‰ä¸€è½®ä¸æ˜¯é—®å¥ç»“å°¾

### 5. need_ragï¼ˆboolï¼‰ï¼š
å½“å‰æ˜¯å¦éœ€è¦å¼•ç”¨å¤–éƒ¨çŸ¥è¯†ï¼Ÿ

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šæ¶‰åŠä¸“ä¸šçŸ¥è¯†ã€äº‹å®ä¿¡æ¯ã€æŠ€å·§æ–¹æ³•ã€å…·ä½“å»ºè®®ç­‰éœ€è¦å¤–éƒ¨çŸ¥è¯†æ”¯æŒçš„å†…å®¹
- Falseï¼šçº¯æƒ…æ„Ÿé™ªä¼´å¯¹è¯ï¼Œä¸éœ€è¦ä¸“ä¸šçŸ¥è¯†

**å…·ä½“ç¤ºä¾‹**ï¼š
- Trueï¼šç”¨æˆ·è¯¢é—®"å¦‚ä½•ç¼“è§£ç„¦è™‘"ã€"æŠ‘éƒç—‡çš„ç—‡çŠ¶æœ‰å“ªäº›"ã€"å†¥æƒ³çš„å…·ä½“æ­¥éª¤"
- Falseï¼šç”¨æˆ·è¡¨è¾¾"æˆ‘ä»Šå¤©å¿ƒæƒ…ä¸å¥½"ã€"æˆ‘å¾ˆéš¾è¿‡"ã€"æˆ‘æƒ³æ‰¾äººèŠèŠ"

### 6. rag_queriesï¼ˆList[str]ï¼‰ï¼š
å¦‚æœneed_ragä¸ºTrueï¼Œåˆ—å‡ºæ£€ç´¢æŸ¥è¯¢è¯ï¼Œå¦åˆ™è¿”å›ç©ºæ•°ç»„[]

**è¦æ±‚**ï¼š
- å¦‚æœneed_ragä¸ºTrueï¼Œæä¾›2-4ä¸ªç›¸å…³çš„æ£€ç´¢å…³é”®è¯
- å¦‚æœneed_ragä¸ºFalseï¼Œè¿”å›ç©ºæ•°ç»„[]

### 7. need_live_searchï¼ˆboolï¼‰ï¼š
å½“å‰æ˜¯å¦éœ€è¦å®æ—¶æœç´¢ä¿¡æ¯ï¼Ÿ

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šæ¶‰åŠå®æ—¶ä¿¡æ¯ã€æœ€æ–°åŠ¨æ€ã€å½“å‰çŠ¶æ€ç­‰éœ€è¦æœç´¢çš„å†…å®¹
- Falseï¼šä¸éœ€è¦å®æ—¶ä¿¡æ¯çš„å¯¹è¯

**é‡è¦æé†’**ï¼šè¯·å…ˆæŸ¥çœ‹ä¸Šé¢"å·²æœç´¢å†…å®¹"éƒ¨åˆ†ï¼Œå¦‚æœå·²æœ‰ç›¸å…³ä¿¡æ¯èƒ½æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œåˆ™ä¸éœ€è¦é‡å¤æœç´¢ã€‚

### 8. live_search_queriesï¼ˆList[str]ï¼‰ï¼š
å¦‚æœneed_live_searchä¸ºTrueï¼Œåˆ—å‡ºæœç´¢æŸ¥è¯¢è¯ï¼Œå¦åˆ™è¿”å›ç©ºæ•°ç»„[]

**è¦æ±‚**ï¼š
- å¦‚æœneed_live_searchä¸ºTrueï¼Œåªæä¾›1ä¸ªæœ€ç²¾å‡†çš„æœç´¢å…³é”®è¯
- å¦‚æœneed_live_searchä¸ºFalseï¼Œè¿”å›ç©ºæ•°ç»„[]
- ä¸¥ç¦æä¾›å¤šä¸ªæœç´¢è¯ï¼Œåªå…è®¸1ä¸ªï¼

**æŸ¥è¯¢è¯ä¼˜åŒ–åŸåˆ™**ï¼š
- å¿…é¡»åŒ…å«å…·ä½“æ—¥æœŸï¼šå¦‚"9æœˆ2æ—¥"ã€"ä»Šå¤©"ã€"ä»Šæ—¥"
- ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åŸè¯ä¸­çš„å…³é”®è¯
- æŸ¥è¯¢è¯è¦ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡8ä¸ªå­—
- é€‰æ‹©æœ€æ ¸å¿ƒã€æœ€é‡è¦çš„å…³é”®è¯


### 9. should_end_conversationï¼ˆboolï¼‰ï¼š
å¯¹è¯å†…å®¹æ˜¯å¦å·²ç»è¶‹äºå®Œæ•´ï¼Œä¸”ç”¨æˆ·æ²¡æœ‰ä¸»åŠ¨å»¶ç»­è¯é¢˜çš„æ„æ„¿ï¼Ÿ

**é‡è¦çº¦æŸ**ï¼šå¦‚æœå½“å‰å¯¹è¯è½®æ•° â‰¤ 3ï¼Œåˆ™æ­¤å€¼å¿…é¡»ä¸º Falseï¼

**åˆ¤æ–­æ ‡å‡†**ï¼š
- Trueï¼šç”¨æˆ·å·²ç»å……åˆ†è¡¨è¾¾äº†å½“å‰è¯é¢˜ï¼Œæƒ…ç»ªè¶‹äºç¨³å®šï¼Œæ²¡æœ‰æå‡ºæ–°é—®é¢˜æˆ–å»¶ç»­è¯é¢˜çš„æ„æ„¿
- Falseï¼šç”¨æˆ·è¿˜åœ¨è¡¨è¾¾è¿‡ç¨‹ä¸­ï¼Œæˆ–è€…æœ‰æ˜æ˜¾æƒ³è¦ç»§ç»­åˆ†äº«ã€è®¨è®ºçš„æ„æ„¿

**å…·ä½“è¡¨ç°**ï¼š
- Trueï¼šç”¨æˆ·è¯´"è°¢è°¢ä½ çš„é™ªä¼´"ã€"æˆ‘æ„Ÿè§‰å¥½å¤šäº†"ã€"æˆ‘æƒ³å…ˆé™ä¸€é™"
- Falseï¼šç”¨æˆ·è¯´"æˆ‘ç°åœ¨æ„Ÿè§‰åˆ°å¹³å’Œ"ã€"æˆ‘å¿ƒæƒ…ä¸é”™"ã€"æˆ‘æœ‰ç‚¹ç´¯"ã€"æˆ‘æƒ³æ‰¾äººèŠèŠ"


## è¿”å›æ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "emotion_type": "negative",
  "user_has_shared_reason": true,
  "ai_has_given_suggestion": false,
  "consecutive_ai_questions": true,
  "need_rag": false,
  "rag_queries": [],
  "need_live_search": false,
  "live_search_queries": [],
  "should_end_conversation": false
}}

**é‡è¦æé†’**ï¼šlive_search_queries æ•°ç»„æœ€å¤šåªèƒ½åŒ…å«1ä¸ªå…ƒç´ ï¼

**å½“å‰å¯¹è¯è½®æ•°**ï¼šç¬¬ {round_index} è½®

è¯·åŸºäºä¸Šè¿°æ ‡å‡†è¿›è¡Œåˆ†æï¼Œç¡®ä¿åˆ¤æ–­å‡†ç¡®ï¼š
"""


def is_question_ending(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä»¥é—®å¥ç»“å°¾"""
    if not text or not isinstance(text, str):
        return False
    
    # æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™ç©ºæ ¼
    cleaned_text = text.strip()
    
    # å®šä¹‰é—®å¥ç»“å°¾æ¨¡å¼
    question_endings = ['å—ï¼Ÿ', 'å‘¢ï¼Ÿ', 'ä»€ä¹ˆï¼Ÿ', 'å§ï¼Ÿ', 'å¦‚ä½•ï¼Ÿ', 'ï¼Ÿ', '?']
    
    # æ£€æŸ¥æ˜¯å¦ä»¥é—®å¥ç»“å°¾
    return any(cleaned_text.endswith(ending) for ending in question_endings)

def check_consecutive_questions(conversation_history: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦è¿ç»­ä¸‰è½®AIå›å¤éƒ½ä»¥é—®å¥ç»“å°¾"""
    if not conversation_history:
        return False
    
    # è§£æå¯¹è¯å†å²ï¼Œæå–AIå›å¤
    ai_messages = []
    lines = conversation_history.split('\n')
    
    for line in lines:
        line = line.strip()
        if line.startswith('â€¢ AI: '):
            # æå–AIå›å¤å†…å®¹
            content = line[6:].strip()  # å»æ‰ "â€¢ AI: " å‰ç¼€
            ai_messages.append(content)
    
    # å¦‚æœAIå›å¤å°‘äºä¸‰è½®ï¼Œè¿”å›False
    if len(ai_messages) < 3:
        return False
    
    # æ£€æŸ¥æœ€è¿‘ä¸‰è½®AIå›å¤æ˜¯å¦éƒ½ä»¥é—®å¥ç»“å°¾
    recent_three = ai_messages[-3:]
    
    for message in recent_three:
        if not is_question_ending(message):
            return False
    
    return True

def analyze_turn(state_summary: str, question: str, round_index: int = 1, searched_content: str = "") -> Dict[str, Any]:
    prompt = ANALYZE_PROMPT.format(state_summary=state_summary, question=question, searched_content=searched_content, round_index=round_index)
    
    # ä¸å†æ‰“å°åˆ†æpromptï¼Œåªæ˜¾ç¤ºåˆ†æç»“æœ

    try:
        result = chat_with_llm(prompt)
        
        # å¤„ç† LLM è¿”å›çš„ Markdown æ ¼å¼ JSON
        if isinstance(result, str):
            json_content = result.strip()
            
            # å¦‚æœè¢« ```json å’Œ ``` åŒ…å›´ï¼Œæå–ä¸­é—´å†…å®¹
            if json_content.startswith('```json') and json_content.endswith('```'):
                json_content = json_content[7:-3].strip()  # ç§»é™¤ ```json å’Œ ```
            elif json_content.startswith('```') and json_content.endswith('```'):
                json_content = json_content[3:-3].strip()  # ç§»é™¤ ``` å’Œ ```
            
            try:
                parsed = json.loads(json_content)
            except json.JSONDecodeError as je:
                logging.error(f"[chat_analysis] JSON è§£æå¤±è´¥: {je}")
                logging.error(f"[chat_analysis] å°è¯•è§£æçš„å†…å®¹: {json_content[:200]}...")
                raise ValueError(f"LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {json_content[:100]}")
        else:
            parsed = result
            
        # ä½¿ç”¨æœ¬åœ°åˆ¤æ–­è¿ç»­é—®å¥ï¼Œæ›¿ä»£LLMåˆ¤æ–­
        consecutive_ai_questions = check_consecutive_questions(state_summary)
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logging.info(f"[æœ¬åœ°åˆ¤æ–­] consecutive_ai_questions: {consecutive_ai_questions}")
        logging.info(f"[æœ¬åœ°åˆ¤æ–­] å¯¹è¯å†å²: {state_summary}")
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºåˆ†æç»“æœ
        analysis_result = {
            "user_has_shared_reason": parsed.get("user_has_shared_reason", False),
            "ai_has_given_suggestion": parsed.get("ai_has_given_suggestion", False),
            "should_end_conversation": parsed.get("should_end_conversation", False),
            "emotion_type": parsed.get("emotion_type", "neutral"),
            "consecutive_ai_questions": consecutive_ai_questions,  # ä½¿ç”¨æœ¬åœ°åˆ¤æ–­
            "need_rag": parsed.get("need_rag", False),
            "rag_queries": parsed.get("rag_queries", []) if parsed.get("need_rag", False) else [],
            "need_live_search": parsed.get("need_live_search", False),
            "live_search_queries": parsed.get("live_search_queries", []) if parsed.get("need_live_search", False) else []
        }
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºåˆ†æç»“æœ
        logging.info("=" * 50)
        logging.info("ğŸ“Š CHAT_ANALYSIS åˆ†æç»“æœ")
        logging.info("=" * 50)
        logging.info(f"æƒ…ç»ªç±»å‹: {analysis_result['emotion_type']}")
        logging.info(f"å·²åˆ†äº«åŸå› : {analysis_result['user_has_shared_reason']}")
        logging.info(f"AIå·²ç»™å»ºè®®: {analysis_result['ai_has_given_suggestion']}")
        logging.info(f"è¿ç»­é—®å¥: {analysis_result['consecutive_ai_questions']}")
        logging.info(f"éœ€è¦RAG: {analysis_result['need_rag']}")
        logging.info(f"éœ€è¦å®æ—¶æœç´¢: {analysis_result['need_live_search']}")
        logging.info(f"å¯¹è¯åº”ç»“æŸ: {analysis_result['should_end_conversation']}")
        if analysis_result['need_rag']:
            logging.info(f"RAGæŸ¥è¯¢è¯: {analysis_result['rag_queries']}")
        if analysis_result['need_live_search']:
            logging.info(f"å®æ—¶æœç´¢æŸ¥è¯¢è¯: {analysis_result['live_search_queries']}")
        logging.info("=" * 50)
        
        return analysis_result
    except Exception as e:
        logging.error(f"[chat_analysis] åˆ†æå¤±è´¥: {e}")
        return {
            "user_has_shared_reason": False,
            "ai_has_given_suggestion": False,
            "should_end_conversation": False,
            "emotion_type": "neutral",
            "consecutive_ai_questions": False,
            "need_rag": False,
            "rag_queries": [],
            "need_live_search": False,
            "live_search_queries": []
        }