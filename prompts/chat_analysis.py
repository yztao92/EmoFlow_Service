# chat_analysis.py
import logging
import json
from typing import Dict, Any
from llm.llm_factory import chat_with_llm
import re

ANALYZE_PROMPT = """
ä½ æ˜¯å¯¹è¯åˆ†æå™¨ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·ä¸AIçš„å¯¹è¯çŠ¶æ€ã€‚è¯·ä»”ç»†é˜…è¯»æ•´ä¸ªå¯¹è¯å†å²ï¼Œå‡†ç¡®åˆ¤æ–­å½“å‰çŠ¶æ€ã€‚

## åˆ†ææ­¥éª¤
1. é€šè¯»å¯¹è¯å†å²ï¼Œç†è§£ç”¨æˆ·æƒ…ç»ªå‘å±•
2. é‡ç‚¹å…³æ³¨ç”¨æˆ·æœ€æ–°è¡¨è¾¾ä¸æ•´ä½“æƒ…ç»ªå€¾å‘  
3. åˆ†æAIçš„å›å¤æ–¹å¼ä¸è¡Œä¸ºç‰¹ç‚¹
4. åŸºäºä»¥ä¸Šåˆ†æåšå‡ºå‡†ç¡®åˆ¤æ–­

## å¯¹è¯å†å²ï¼š
{state_summary}

## å½“å‰ç”¨æˆ·è¾“å…¥ï¼š
{question}

## ç›¸å…³æœç´¢ä¿¡æ¯ï¼š
{cached_search_info}

# ä¸€ã€æƒ…ç»ªçŠ¶æ€åˆ†æ

## 1. emotion_typeï¼ˆå¿…é€‰å…¶ä¸€ï¼‰ï¼š
è¯†åˆ«ç”¨æˆ·åœ¨æ•´ä¸ªå¯¹è¯ä¸­çš„ä¸»è¦æƒ…ç»ªå€¾å‘ï¼š
- "tired"ï¼šè¡¨è¾¾ç–²æƒ«ã€å€¦æ€ ã€è™šæ— ã€æ²¡åŠ›æ°”
- "negative"ï¼šè¡¨è¾¾æ‚²ä¼¤ã€ç„¦è™‘ã€ç—›è‹¦ã€å¤±è½ã€éš¾è¿‡
- "angry"ï¼šè¡¨è¾¾æ„¤æ€’ã€å§”å±ˆã€ä¸æ»¡ã€è¢«å†’çŠ¯
- "positive"ï¼šè¡¨è¾¾å¼€å¿ƒã€æ¿€åŠ¨ã€æ»¡è¶³ã€å…´å¥‹
- "neutral"ï¼šæƒ…ç»ªä¸æ˜æ˜¾æˆ–çœŸæ­£çš„ä¸­æ€§è¡¨è¾¾

**æç¤º**ï¼šå¿½ç•¥å®¢å¥—è¯ï¼Œè¯†åˆ«çœŸå®æƒ…ç»ªè¡¨è¾¾

# äºŒã€å¯¹è¯å†…å®¹åˆ†æ

## 2. user_has_shared_reasonï¼ˆboolï¼‰ï¼š
ç”¨æˆ·æ˜¯å¦å·²è¯´æ˜å…·ä½“æƒ…ç»ªåŸå› æˆ–äº‹ä»¶ï¼Ÿ

**æç¤º**ï¼šæ˜¯å¦åŒ…å«æ˜ç¡®äººäº‹æ—¶åœ°ç‰©ï¼Œè€Œéä»…æè¿°æƒ…ç»ªçŠ¶æ€

**ç¤ºä¾‹å¯¹æ¯”**ï¼š
- Trueï¼š"å¥³å‹ä¸å…³å¿ƒæˆ‘"ã€"è€ƒè¯•å¤±è´¥"ã€"å’ŒåŒäº‹åµæ¶äº†"
- Falseï¼š"æˆ‘å¾ˆéš¾è¿‡"ã€"æƒ…ç»ªä½è½"ã€"ä¸å¼€å¿ƒ"

## 3. ai_has_given_suggestionï¼ˆboolï¼‰ï¼š
AIæ˜¯å¦å·²æä¾›å…·ä½“å»ºè®®æˆ–è¡ŒåŠ¨æ–¹æ¡ˆï¼Ÿ

**æç¤º**ï¼šæ˜¯å¦å‡ºç°è¡ŒåŠ¨æ€§å»ºè®®ï¼Œè€Œéæƒ…ç»ªå›åº”æˆ–è¯¢é—®

**ç¤ºä¾‹å¯¹æ¯”**ï¼š
- Trueï¼š"è¯•ç€æ²Ÿé€šä¸€ä¸‹"ã€"å¯ä»¥å†™æ—¥è®°"ã€"å»ºè®®ä½ ä¼‘æ¯ä¸€ä¸‹"
- Falseï¼š"æˆ‘ç†è§£ä½ çš„æ„Ÿå—"ã€"ä½ æƒ³è¯´è¯´åŸå› å—ï¼Ÿ"

# ä¸‰ã€å®æ—¶ä¿¡æ¯æ£€ç´¢éœ€æ±‚åˆ†æ

## 4. need_live_searchï¼ˆboolï¼‰ï¼š
å½“å‰å¯¹è¯æ˜¯å¦éœ€è¦æŸ¥è¯¢å®æ—¶ä¿¡æ¯ï¼Ÿ

**åˆ¤æ–­æµç¨‹**ï¼š
1. é¦–å…ˆæ£€æŸ¥ä¸Šé¢çš„"ç›¸å…³æœç´¢ä¿¡æ¯"æ˜¯å¦å·²ç»åŒ…å«ç”¨æˆ·éœ€è¦çš„ä¿¡æ¯
2. å¦‚æœå·²æœ‰ä¿¡æ¯èƒ½æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œåˆ™ä¸éœ€è¦æ–°çš„æœç´¢
3. å¦‚æœå·²æœ‰ä¿¡æ¯ä¸è¶³æˆ–è¿‡æ—¶ï¼Œä¸”ç”¨æˆ·é—®é¢˜æ¶‰åŠ**å¤–éƒ¨äº‹å®ã€æ–°é—»ã€çŠ¶æ€**ç­‰å®æ—¶ä¿¡æ¯æ—¶ï¼Œæ‰éœ€æœç´¢

**æç¤º**ï¼šä»…å‡ºç°"ä»Šå¤©""ç°åœ¨"ç­‰è¯ä¸è¶³ä»¥åˆ¤æ–­ä¸º Trueï¼Œè¿˜éœ€åˆ¤æ–­æ˜¯å¦ä¸ºä¿¡æ¯æŸ¥è¯¢ç±»é—®é¢˜ã€‚

**ç¤ºä¾‹**ï¼š
- Trueï¼š"ä»Šå¤©è‚¡å¸‚æ€ä¹ˆæ ·"ï¼ˆä¸”ä¸Šé¢æ²¡æœ‰ç›¸å…³è‚¡å¸‚ä¿¡æ¯ï¼‰
- Falseï¼š"ä»Šå¤©è‚¡å¸‚æ€ä¹ˆæ ·"ï¼ˆä½†ä¸Šé¢å·²æœ‰æœ€æ–°çš„è‚¡å¸‚ä¿¡æ¯ï¼‰
- Falseï¼š"æˆ‘ä»Šå¤©å¾ˆéš¾è¿‡"ã€"æˆ‘æœ€è¿‘å¾ˆç„¦è™‘"

## 5. has_timeliness_requirementï¼ˆboolï¼‰ï¼š
æ£€ç´¢ä¿¡æ¯æ˜¯å¦å…·å¤‡æ—¶æ•ˆæ€§è¦æ±‚ï¼Ÿ

**æç¤º**ï¼šå‡ºç°"ç°åœ¨""ä»Šå¤©""åˆšåˆš""æœ€æ–°"å³ä¸º True

**ç¤ºä¾‹**ï¼š
- Trueï¼š"ä»Šå¤©å¤©æ°”å¦‚ä½•"ã€"æœ€è¿‘çš„æ–°é—»"
- Falseï¼š"ä»€ä¹ˆæ˜¯CBT"ã€"å¦‚ä½•ç¼“è§£ç„¦è™‘"

## 6. live_search_queriesï¼ˆList[str]ï¼‰ï¼š
è‹¥ need_live_search ä¸º Trueï¼Œåˆ—å‡ºæœç´¢å…³é”®è¯ï¼Œå¦åˆ™è¿”å›ç©ºæ•°ç»„ã€‚
ä¸è¦ç›´æ¥ç”¨ç”¨æˆ·åŸè¯ä½œä¸ºæœç´¢å…³é”®è¯ï¼Œè€Œæ˜¯è¦æ ¹æ®ç”¨æˆ·åŸè¯è¿›è¡Œæ€»ç»“ï¼Œç”Ÿæˆä¸€ä¸ªæœ€ç²¾å‡†çš„æœç´¢å…³é”®è¯ã€‚

**è¦æ±‚**ï¼š
- æä¾› 1 ä¸ªæœ€ç²¾å‡†çš„æœç´¢å…³é”®è¯
- **ä¸¥æ ¼ç¦æ­¢**ï¼šå…³é”®è¯ä¸­ç»å¯¹ä¸èƒ½åŒ…å«ä»»ä½•æ—¶é—´ç›¸å…³è¯æ±‡ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
  - æ—¶é—´è¯ï¼š"ä»Šå¤©"ã€"å½“å‰"ã€"ç°åœ¨"ã€"æœ€æ–°"ã€"æœ€è¿‘"
  - æ—¥æœŸè¯ï¼š"2025å¹´"ã€"9æœˆ5æ—¥"ã€"ä»Šæ—¥"ã€"ç°åœ¨"
  - å…¶ä»–æ—¶é—´è¡¨è¾¾ï¼š"ç›®å‰"ã€"çœ¼ä¸‹"ã€"æ­¤æ—¶"
- ç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ æ—¶æ•ˆæ€§å‰ç¼€ï¼Œä½ åªéœ€è¦æä¾›çº¯ç²¹çš„ä¸»é¢˜å…³é”®è¯

# å››ã€çŸ¥è¯†è¡¥å……éœ€æ±‚åˆ†æ

## 7. need_ragï¼ˆboolï¼‰ï¼š
å½“å‰å¯¹è¯æ˜¯å¦æ¶‰åŠå¿ƒç†çŸ¥è¯†è¡¥å……ï¼Ÿ

**æç¤º**ï¼šç”¨æˆ·æé—®æ¶‰åŠä¸“ä¸šå¿ƒç†çŸ¥è¯†ã€æ²»ç–—æ–¹å¼ã€æŠ€å·§å»ºè®®ç­‰

**ç¤ºä¾‹**ï¼š
- Trueï¼š"å¦‚ä½•ç¼“è§£ç„¦è™‘"ã€"è®¤çŸ¥è¡Œä¸ºç–—æ³•æ˜¯ä»€ä¹ˆ"
- Falseï¼š"æˆ‘æ„Ÿè§‰ä½è½"ã€"æˆ‘æƒ³æ‰¾äººèŠèŠ"

## 8. rag_queriesï¼ˆList[str]ï¼‰ï¼š
è‹¥ need_rag ä¸º Trueï¼Œç”Ÿæˆå¯¹è¯å†å²ä¸å½“å‰ç”¨æˆ·è¾“å…¥çš„æ‘˜è¦ï¼Œå¦åˆ™è¿”å›ç©ºæ•°ç»„

**è¦æ±‚**ï¼š
- æä¾› 1 å¥è¯æ‘˜è¦ï¼ŒåŒ…å«ç”¨æˆ·é—®é¢˜èƒŒæ™¯å’Œæ ¸å¿ƒéœ€æ±‚
- æ‘˜è¦åº”æ¶µç›–å†å²å¯¹è¯å’Œç”¨æˆ·æœ€æ–°è¾“å…¥çš„æ•´ä½“æƒ…å†µ
- ç¤ºä¾‹ï¼š"ç”¨æˆ·å› å·¥ä½œå‹åŠ›å¤§æ„Ÿåˆ°ç„¦è™‘ï¼Œè¯¢é—®å¦‚ä½•ç¼“è§£ç„¦è™‘æƒ…ç»ª"

# äº”ã€å¯¹è¯æµç¨‹æ§åˆ¶

## 9. should_end_conversationï¼ˆboolï¼‰ï¼š
å½“å‰è¯é¢˜æ˜¯å¦å·²å®Œæ•´ã€ç”¨æˆ·æ— å»¶ç»­æ„æ„¿ï¼Ÿ

**çº¦æŸ**ï¼šè‹¥å½“å‰å¯¹è¯è½®æ•° â‰¤3ï¼Œ**å¿…é¡»ä¸º False**

**æç¤º**ï¼šç”¨æˆ·è¡¨è¾¾æ„Ÿè°¢ã€é‡Šæ”¾ã€æš‚åœå€¾å‘ï¼Œå¯åˆ¤æ–­ç»“æŸ  
**ç¤ºä¾‹**ï¼š
- Trueï¼š"è°¢è°¢ä½ çš„é™ªä¼´"ã€"æˆ‘æ„Ÿè§‰å¥½å¤šäº†"ã€"æˆ‘æƒ³å…ˆé™ä¸€é™"
- Falseï¼š"æˆ‘ç°åœ¨æ„Ÿè§‰åˆ°å¹³å’Œ"ã€"æˆ‘æƒ³æ‰¾äººèŠèŠ"

## è¿”å›æ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "emotion_type": "negative",
  "user_has_shared_reason": true,
  "ai_has_given_suggestion": false,
  "need_live_search": false,
  "has_timeliness_requirement": false,
  "live_search_queries": [],
  "need_rag": false,
  "rag_queries": ["ç”¨æˆ·å› å·¥ä½œå‹åŠ›å¤§æ„Ÿåˆ°ç„¦è™‘ï¼Œè¯¢é—®å¦‚ä½•ç¼“è§£ç„¦è™‘æƒ…ç»ª"],
  "should_end_conversation": false
}}

**å½“å‰å¯¹è¯è½®æ•°**ï¼šç¬¬ {round_index} è½®

è¯·æŒ‰ä»¥ä¸Šæ ‡å‡†é€é¡¹åˆ¤æ–­ï¼Œä¸¥æ ¼è¿”å› JSON ç»“æ„ç»“æœã€‚
"""


def is_question_ending(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä»¥é—®å¥ç»“å°¾"""
    if not text or not isinstance(text, str):
        return False
    
    # æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™ç©ºæ ¼
    cleaned_text = text.strip()
    
    # å®šä¹‰é—®å¥ç»“å°¾æ¨¡å¼
    question_endings = ['å—ï¼Ÿ', 'å‘¢ï¼Ÿ', 'ä»€ä¹ˆï¼Ÿ', 'å§ï¼Ÿ', 'å¦‚ä½•ï¼Ÿ', 'ï¼Ÿ', '?']
    
    # æ£€æŸ¥æ˜¯å¦ä»¥é—®å¥ç»“å°¾
    return any(cleaned_text.endswith(ending) for ending in question_endings)

def check_consecutive_questions(conversation_history: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦è¿ç»­ä¸‰è½®AIå›å¤éƒ½ä»¥é—®å¥ç»“å°¾"""
    if not conversation_history:
        return False
    
    # è§£æå¯¹è¯å†å²ï¼Œæå–AIå›å¤
    ai_messages = []
    lines = conversation_history.split('\n')
    
    for line in lines:
        line = line.strip()
        if line.startswith('â€¢ AI: '):
            # æå–AIå›å¤å†…å®¹
            content = line[6:].strip()  # å»æ‰ "â€¢ AI: " å‰ç¼€
            ai_messages.append(content)
    
    # å¦‚æœAIå›å¤å°‘äºä¸‰è½®ï¼Œè¿”å›False
    if len(ai_messages) < 3:
        return False
    
    # æ£€æŸ¥æœ€è¿‘ä¸‰è½®AIå›å¤æ˜¯å¦éƒ½ä»¥é—®å¥ç»“å°¾
    recent_three = ai_messages[-3:]
    
    for message in recent_three:
        if not is_question_ending(message):
            return False
    
    return True

def analyze_turn(state_summary: str, question: str, round_index: int = 1, session_id: str = None) -> Dict[str, Any]:
    # è·å–ç¼“å­˜çš„æœç´¢ä¿¡æ¯
    cached_search_info = ""
    if session_id:
        try:
            from llm.search_cache import get_cached_search_results
            cached_results = get_cached_search_results(session_id)
            if cached_results:
                # æ ¼å¼åŒ–ç¼“å­˜ä¿¡æ¯
                search_items = []
                for result in cached_results[-3:]:  # åªå–æœ€è¿‘3æ¬¡æœç´¢
                    search_items.append(f"â€¢ æŸ¥è¯¢ï¼š{result['query']}\nâ€¢ ç»“æœï¼š{result['result']}")
                cached_search_info = "\n\n".join(search_items)
                logging.info(f"[chat_analysis] å·²åŠ è½½ {len(cached_results)} æ¡ç¼“å­˜æœç´¢ä¿¡æ¯")
        except Exception as e:
            logging.warning(f"[chat_analysis] è·å–ç¼“å­˜æœç´¢ä¿¡æ¯å¤±è´¥: {e}")
    
    prompt = ANALYZE_PROMPT.format(
        state_summary=state_summary, 
        question=question, 
        round_index=round_index,
        cached_search_info=cached_search_info
    )
    
    # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„åˆ†æpromptï¼ˆå·²ç¦ç”¨ï¼‰
    # logging.info("=" * 80)
    # logging.info("ğŸ“‹ CHAT_ANALYSIS å®Œæ•´Prompt")
    # logging.info("=" * 80)
    # logging.info(prompt)
    # logging.info("=" * 80)

    try:
        result = chat_with_llm(prompt)
        
        # å¤„ç† LLM è¿”å›çš„ Markdown æ ¼å¼ JSON
        if isinstance(result, str):
            json_content = result.strip()
            
            # å¦‚æœè¢« ```json å’Œ ``` åŒ…å›´ï¼Œæå–ä¸­é—´å†…å®¹
            if json_content.startswith('```json') and json_content.endswith('```'):
                json_content = json_content[7:-3].strip()  # ç§»é™¤ ```json å’Œ ```
            elif json_content.startswith('```') and json_content.endswith('```'):
                json_content = json_content[3:-3].strip()  # ç§»é™¤ ``` å’Œ ```
            
            try:
                parsed = json.loads(json_content)
            except json.JSONDecodeError as je:
                logging.error(f"[chat_analysis] JSON è§£æå¤±è´¥: {je}")
                logging.error(f"[chat_analysis] å°è¯•è§£æçš„å†…å®¹: {json_content[:200]}...")
                raise ValueError(f"LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {json_content[:100]}")
        else:
            parsed = result
            
        # ä½¿ç”¨æœ¬åœ°åˆ¤æ–­è¿ç»­é—®å¥ï¼Œæ›¿ä»£LLMåˆ¤æ–­
        consecutive_ai_questions = check_consecutive_questions(state_summary)
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logging.info(f"[æœ¬åœ°åˆ¤æ–­] consecutive_ai_questions: {consecutive_ai_questions}")
        logging.info(f"[æœ¬åœ°åˆ¤æ–­] å¯¹è¯å†å²: {state_summary}")
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºåˆ†æç»“æœ
        analysis_result = {
            "user_has_shared_reason": parsed.get("user_has_shared_reason", False),
            "ai_has_given_suggestion": parsed.get("ai_has_given_suggestion", False),
            "should_end_conversation": parsed.get("should_end_conversation", False),
            "emotion_type": parsed.get("emotion_type", "neutral"),
            "consecutive_ai_questions": consecutive_ai_questions,  # ä½¿ç”¨æœ¬åœ°åˆ¤æ–­
            "need_rag": parsed.get("need_rag", False),
            "rag_queries": parsed.get("rag_queries", []) if parsed.get("need_rag", False) else [],
            "need_live_search": parsed.get("need_live_search", False),
            "live_search_queries": parsed.get("live_search_queries", []) if parsed.get("need_live_search", False) else [],
            "has_timeliness_requirement": parsed.get("has_timeliness_requirement", False)
        }
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºåˆ†æç»“æœ
        logging.info("=" * 50)
        logging.info("ğŸ“Š CHAT_ANALYSIS åˆ†æç»“æœ")
        logging.info("=" * 50)
        logging.info(f"æƒ…ç»ªç±»å‹: {analysis_result['emotion_type']}")
        logging.info(f"å·²åˆ†äº«åŸå› : {analysis_result['user_has_shared_reason']}")
        logging.info(f"AIå·²ç»™å»ºè®®: {analysis_result['ai_has_given_suggestion']}")
        logging.info(f"è¿ç»­é—®å¥: {analysis_result['consecutive_ai_questions']}")
        logging.info(f"éœ€è¦RAG: {analysis_result['need_rag']}")
        logging.info(f"éœ€è¦å®æ—¶æœç´¢: {analysis_result['need_live_search']}")
        logging.info(f"æ—¶æ•ˆæ€§è¦æ±‚: {analysis_result['has_timeliness_requirement']}")
        logging.info(f"å¯¹è¯åº”ç»“æŸ: {analysis_result['should_end_conversation']}")
        if analysis_result['need_rag']:
            logging.info(f"RAGæŸ¥è¯¢è¯: {analysis_result['rag_queries']}")
        if analysis_result['need_live_search']:
            logging.info(f"å®æ—¶æœç´¢æŸ¥è¯¢è¯: {analysis_result['live_search_queries']}")
        logging.info("=" * 50)
        
        return analysis_result
    except Exception as e:
        logging.error(f"[chat_analysis] åˆ†æå¤±è´¥: {e}")
        return {
            "user_has_shared_reason": False,
            "ai_has_given_suggestion": False,
            "should_end_conversation": False,
            "emotion_type": "neutral",
            "consecutive_ai_questions": False,
            "need_rag": False,
            "rag_queries": [],
            "need_live_search": False,
            "live_search_queries": [],
            "has_timeliness_requirement": False
        }