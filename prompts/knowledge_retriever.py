# prompts/knowledge_retriever.py
from typing import List, Dict, Any
import logging
from llm.llm_factory import chat_with_llm

MIN_SIM = 0.50
TOP_K = 15

# æŒ‰ä½ çš„å®ç°æ›¿æ¢
from vectorstore.qwen_vectorstore import get_qwen_vectorstore

def _distill_snippets(docs: List[Dict[str, Any]], max_items:int=3) -> List[str]:
    if not docs:
        return []
    joined = "\n\n".join([f"ã€{i+1}ã€‘{d.get('content','')[:600]}" for i,d in enumerate(docs[:5])])
    logging.info("ğŸ“ [æç‚¼] è¾“å…¥ææ–™æ¡æ•°=%d", len(docs))
    prompt = f"""è¯·ä»ä»¥ä¸‹ææ–™æç‚¼ 2â€“3 æ¡â€œå¯æ‰§è¡Œå»ºè®®â€ï¼Œå£è¯­åŒ–ï¼Œæ¯æ¡â‰¤20å­—ã€‚
é¿å…ç©ºè¯ã€è¯Šæ–­æˆ–å¤„æ–¹ï¼Œä¸è¦å¸¦æ¥æºå£å»ã€‚

ææ–™ï¼š
{joined}

åªè¾“å‡ºæ¡ç›®ï¼Œæ¯è¡Œä¸€æ¡ã€‚
"""
    res = chat_with_llm(prompt)
    answer = res.get("answer", "")
    
    # ç¡®ä¿answeræ˜¯å­—ç¬¦ä¸²ç±»å‹
    if not isinstance(answer, str):
        logging.warning(f"âš ï¸ [æç‚¼] answerä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(answer)}, å†…å®¹: {answer}")
        answer = str(answer) if answer else ""
    
    bullets = [line.strip(" -â€¢Â·").strip() for line in (answer.split("\n")) if line.strip()]
    return bullets[:max_items]

def retrieve_bullets(queries: List[str]) -> List[str]:
    if not queries:
        logging.info("âš ï¸ [æ£€ç´¢] æ—  queriesï¼Œè¿”å›ç©º")
        return []

    logging.info(f"ğŸš€ [æ£€ç´¢] å¼€å§‹çŸ¥è¯†æ£€ç´¢ï¼ŒæŸ¥è¯¢æ•°é‡: {len(queries)}")
    logging.info(f"ğŸ” [æ£€ç´¢] æŸ¥è¯¢åˆ—è¡¨: {queries}")
    
    vs = get_qwen_vectorstore()
    cands: List[Dict[str,Any]] = []

    for i, qtext in enumerate(queries):
        logging.info(f"ğŸ“ [æ£€ç´¢] å¤„ç†ç¬¬ {i+1}/{len(queries)} ä¸ªæŸ¥è¯¢")
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„æŸ¥è¯¢
        if isinstance(qtext, dict):
            qtext = qtext.get("q", "")
            logging.info(f"ğŸ” [æ£€ç´¢] ä»å­—å…¸æå–æŸ¥è¯¢: '{qtext}'")
        elif not isinstance(qtext, str):
            logging.warning(f"âš ï¸ [æ£€ç´¢] qtextä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(qtext)}, å†…å®¹: {qtext}")
            qtext = str(qtext) if qtext else ""
        
        if not qtext:
            continue
        
        qtext = qtext.strip()
        if not qtext:
            continue
        
        logging.info(f"ğŸ” [æ£€ç´¢] æ‰§è¡Œå‘é‡æœç´¢: '{qtext}'")
        
        # è°ƒç”¨å‘é‡åº“æœç´¢ï¼ˆå»æ‰top_kå‚æ•°ï¼‰
        try:
            hits = vs.search(qtext)
            logging.info(f"âœ… [æ£€ç´¢] æœç´¢å®Œæˆ: '{qtext}' â†’ æ‰¾åˆ° {len(hits)} æ¡ç»“æœ")
            
            # æ‰“å°å‰3ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
            for j, hit in enumerate(hits[:3]):
                similarity = hit.get('similarity', 0)
                title = hit.get('title', 'æ— æ ‡é¢˜')[:50]
                logging.info(f"  ğŸ“Š [æ£€ç´¢] ç»“æœ {j+1}: ç›¸ä¼¼åº¦ {similarity:.3f} - {title}...")
            
            cands.extend(hits)
            
        except Exception as e:
            logging.error(f"âŒ [æ£€ç´¢] æœç´¢å¤±è´¥: '{qtext}' - é”™è¯¯: {e}")
            continue

    # å»é‡ + æŒ‰ç›¸ä¼¼åº¦é™åº
    seen, uniq = set(), []
    for d in sorted(cands, key=lambda x: x.get("similarity",0), reverse=True):
        doc_id = d.get("id") or hash(d.get("content","")[:200])
        if doc_id in seen:
            continue
        seen.add(doc_id)
        uniq.append(d)

    # é˜ˆå€¼è¿‡æ»¤
    filtered = [d for d in uniq if d.get("similarity",0) >= MIN_SIM]
    logging.info("âœ… [é˜ˆå€¼] é€šè¿‡=%d / å»é‡å=%d (é˜ˆå€¼=%.2f)", len(filtered), len(uniq), MIN_SIM)

    return _distill_snippets(filtered, max_items=3)