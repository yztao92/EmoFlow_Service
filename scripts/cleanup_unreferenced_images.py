#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†æœªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶
åŠŸèƒ½ï¼šåˆ é™¤uploadæ–‡ä»¶å¤¹ä¸­æœªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶ï¼Œä¿ç•™èŠå¤©è®°å½•
ä½œè€…ï¼šEmoFlow Team
åˆ›å»ºæ—¶é—´ï¼š2025-09-17
"""

import os
import sys
import logging
from datetime import datetime, timezone, timedelta
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database_models.database import Base
from database_models.image import Image
from database_models.journal import Journal

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cleanup_unreferenced_images.log'),
        logging.StreamHandler()
    ]
)

def get_database_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    db_path = os.path.join(os.path.dirname(__file__), "..", "database", "users.db")
    
    if not os.path.exists(db_path):
        logging.error(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return None
    
    engine = create_engine(f"sqlite:///{db_path}")
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    return SessionLocal()

def get_referenced_image_filenames():
    """è·å–æ‰€æœ‰è¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶å"""
    db = get_database_connection()
    if not db:
        return set()
    
    try:
        # æŸ¥è¯¢æ‰€æœ‰æ—¥è®°ä¸­çš„å›¾ç‰‡ID
        journals = db.query(Journal).filter(Journal.images.isnot(None)).all()
        
        referenced_image_ids = set()
        for journal in journals:
            if journal.images:
                # è§£æé€—å·åˆ†éš”çš„å›¾ç‰‡ID
                image_ids = journal.images.split(",")
                for image_id in image_ids:
                    try:
                        referenced_image_ids.add(int(image_id.strip()))
                    except ValueError:
                        logging.warning(f"âš ï¸ æ— æ•ˆçš„å›¾ç‰‡ID: {image_id}")
        
        logging.info(f"ğŸ“Š æ‰¾åˆ° {len(referenced_image_ids)} ä¸ªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡ID")
        
        # æ ¹æ®å›¾ç‰‡IDæŸ¥è¯¢æ–‡ä»¶å
        if referenced_image_ids:
            images = db.query(Image.filename).filter(Image.id.in_(referenced_image_ids)).all()
            referenced_filenames = {img.filename for img in images}
            logging.info(f"ğŸ“Š æ‰¾åˆ° {len(referenced_filenames)} ä¸ªè¢«å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶å")
        else:
            referenced_filenames = set()
            logging.info("ğŸ“Š æ²¡æœ‰å›¾ç‰‡è¢«æ—¥è®°å¼•ç”¨")
        
        return referenced_filenames
        
    except Exception as e:
        logging.error(f"âŒ æŸ¥è¯¢è¢«å¼•ç”¨å›¾ç‰‡å¤±è´¥: {e}")
        return set()
    finally:
        db.close()

def get_filesystem_image_filenames():
    """è·å–æ–‡ä»¶ç³»ç»Ÿä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å"""
    upload_dir = os.path.join(os.path.dirname(__file__), "..", "uploads", "images")
    
    if not os.path.exists(upload_dir):
        logging.warning(f"âš ï¸ ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨: {upload_dir}")
        return set()
    
    filenames = set()
    
    # éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•
    for user_dir in os.listdir(upload_dir):
        user_path = os.path.join(upload_dir, user_dir)
        if os.path.isdir(user_path):
            # éå†ç”¨æˆ·ç›®å½•ä¸­çš„æ–‡ä»¶
            for filename in os.listdir(user_path):
                if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
                    filenames.add(filename)
    
    logging.info(f"ğŸ“Š æ–‡ä»¶ç³»ç»Ÿä¸­æœ‰ {len(filenames)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
    return filenames

def cleanup_unreferenced_images(dry_run=False):
    """æ¸…ç†æœªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶"""
    logging.info("=" * 60)
    logging.info("ğŸ§¹ å¼€å§‹æ¸…ç†æœªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶")
    logging.info("=" * 60)
    
    # è·å–è¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶å
    referenced_filenames = get_referenced_image_filenames()
    
    # è·å–æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å
    filesystem_filenames = get_filesystem_image_filenames()
    
    # æ‰¾å‡ºæœªè¢«å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶
    unreferenced_filenames = filesystem_filenames - referenced_filenames
    
    logging.info(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
    logging.info(f"   - æ–‡ä»¶ç³»ç»Ÿå›¾ç‰‡æ•°: {len(filesystem_filenames)}")
    logging.info(f"   - è¢«æ—¥è®°å¼•ç”¨æ•°: {len(referenced_filenames)}")
    logging.info(f"   - æœªè¢«å¼•ç”¨æ•°: {len(unreferenced_filenames)}")
    
    if not unreferenced_filenames:
        logging.info("âœ… æ‰€æœ‰å›¾ç‰‡éƒ½è¢«æ—¥è®°å¼•ç”¨ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # è®¡ç®—å¯é‡Šæ”¾çš„å­˜å‚¨ç©ºé—´
    total_size = 0
    upload_dir = os.path.join(os.path.dirname(__file__), "..", "uploads", "images")
    
    for user_dir in os.listdir(upload_dir):
        user_path = os.path.join(upload_dir, user_dir)
        if os.path.isdir(user_path):
            for filename in unreferenced_filenames:
                file_path = os.path.join(user_path, filename)
                if os.path.exists(file_path):
                    total_size += os.path.getsize(file_path)
    
    logging.info(f"ğŸ’¾ å¯é‡Šæ”¾å­˜å‚¨ç©ºé—´: {total_size / 1024 / 1024:.2f} MB")
    
    if dry_run:
        logging.info("ğŸ” æ¨¡æ‹Ÿæ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")
        for filename in sorted(unreferenced_filenames):
            logging.info(f"   - å°†åˆ é™¤: {filename}")
        return
    
    # ç¡®è®¤åˆ é™¤
    logging.info(f"ğŸ—‘ï¸ å‡†å¤‡åˆ é™¤ {len(unreferenced_filenames)} ä¸ªæœªè¢«å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶...")
    
    deleted_count = 0
    failed_count = 0
    freed_space = 0
    
    for filename in sorted(unreferenced_filenames):
        # åœ¨æ‰€æœ‰ç”¨æˆ·ç›®å½•ä¸­æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡ä»¶
        for user_dir in os.listdir(upload_dir):
            user_path = os.path.join(upload_dir, user_dir)
            if os.path.isdir(user_path):
                file_path = os.path.join(user_path, filename)
                if os.path.exists(file_path):
                    try:
                        file_size = os.path.getsize(file_path)
                        os.remove(file_path)
                        deleted_count += 1
                        freed_space += file_size
                        logging.info(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {filename} ({file_size} bytes)")
                        break  # æ‰¾åˆ°å¹¶åˆ é™¤åè·³å‡ºå¾ªç¯
                    except Exception as e:
                        logging.error(f"âŒ åˆ é™¤å¤±è´¥ {filename}: {e}")
                        failed_count += 1
    
    logging.info(f"âœ… åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")
    logging.info(f"ğŸ’¾ é‡Šæ”¾ç©ºé—´: {freed_space / 1024 / 1024:.2f} MB")
    logging.info("=" * 60)
    logging.info("ğŸ‰ æœªè¢«å¼•ç”¨å›¾ç‰‡æ–‡ä»¶æ¸…ç†å®Œæˆ")
    logging.info("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¸…ç†æœªè¢«æ—¥è®°å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶')
    parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶')
    
    args = parser.parse_args()
    
    try:
        cleanup_unreferenced_images(dry_run=args.dry_run)
    except KeyboardInterrupt:
        logging.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†è¿‡ç¨‹å¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
