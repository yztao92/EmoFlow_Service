# llm/zhipu_llm.py - æ™ºè°±AI LLM è°ƒç”¨å°è£…

import os
import requests
from dotenv import load_dotenv

load_dotenv()
ZHIPU_API_KEY = os.getenv("ZHIPUAI_API_KEY")
ZHIPU_API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

def zhipu_chat_llm(prompt: str) -> dict:
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {ZHIPU_API_KEY}"
    }

    payload = {
        "model": "glm-4",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå–„è§£äººæ„çš„æƒ…ç»ªæ—¥è®°åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
    }

    try:
        response = requests.post(ZHIPU_API_URL, headers=headers, json=payload)
        print("ğŸ§  Zhipu LLM çŠ¶æ€ç :", response.status_code)
        print("ğŸ§  Zhipu LLM è¿”å›å†…å®¹:", response.text)

        if response.status_code == 200:
            data = response.json()
            return {
                "answer": data["choices"][0]["message"]["content"].strip()
            }
        else:
            raise ValueError(f"è°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

    except Exception as e:
        print("[âŒ ERROR] LLM æ—¥è®°ç”Ÿæˆå¤±è´¥:", e)
        return {
            "answer": "ç”Ÿæˆå¤±è´¥"
        }