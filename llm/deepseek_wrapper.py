# File: llm/deepseek_wrapper.py

import os
import requests
from dotenv import load_dotenv
from langchain_core.language_models.chat_models import BaseChatModel
from langchain.schema import AIMessage, HumanMessage, SystemMessage, ChatResult, ChatGeneration

load_dotenv()
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

class DeepSeekLLM(BaseChatModel):
    """
    Wrapper for DeepSeek Chat API.
    """

    def _call(self, messages, **kwargs):
        # Debug: æ‰“å°å½“å‰ä½¿ç”¨çš„ API Keyï¼Œç¡®è®¤æ˜¯å¦æ­£ç¡®
        print("ğŸ”‘ Using DeepSeek key:", DEEPSEEK_API_KEY)

        # æ„é€  DeepSeek API è¯·æ±‚
        url = "https://api.deepseek.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json",
        }
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        converted_messages = []
        for m in messages:
            if isinstance(m, HumanMessage):
                role = "user"
            elif isinstance(m, AIMessage):
                role = "assistant"
            elif isinstance(m, SystemMessage):
                role = "system"
            else:
                raise ValueError(f"Unsupported message type: {type(m)}")
                
            converted_messages.append({
                "role": role,
                "content": m.content
            })
        
        payload = {
            "model": "deepseek-chat",
            "messages": converted_messages,
            **kwargs  # å…è®¸ä¼ é€’å…¶ä»–å‚æ•°
        }
        
        try:
            resp = requests.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()
            return data["choices"][0]["message"]["content"]
        except requests.exceptions.RequestException as e:
            raise Exception(f"API request failed: {str(e)}")
        except (KeyError, IndexError) as e:
            raise Exception(f"Unexpected API response format: {str(e)}")

    def _generate(self, messages, **kwargs) -> ChatResult:
        """
        BaseChatModel è¦æ±‚å®ç°çš„æŠ½è±¡æ–¹æ³•ï¼Œç”¨æ¥æ”¯æŒ .generate æ¥å£ã€‚
        æˆ‘ä»¬å†…éƒ¨ç›´æ¥è°ƒç”¨ _callï¼Œå†æŠŠç»“æœå°è£…æˆ ChatResultã€‚
        """
        content = self._call(messages, **kwargs)
        # ç”¨ AIMessage å°è£…
        ai_msg = AIMessage(content=content)
        gen = ChatGeneration(message=ai_msg)
        # ChatResult çš„ generations æ˜¯ List[List[ChatGeneration]]
        return ChatResult(generations=[[gen]])

    @property
    def _llm_type(self) -> str:
        return "deepseek-chat"