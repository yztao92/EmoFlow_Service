# File: llm/llm_factory.py
# åŠŸèƒ½ï¼šLLMå·¥å‚ï¼Œç»Ÿä¸€ç®¡ç†ä¸åŒçš„LLMè°ƒç”¨
# å®ç°ï¼šæä¾›ç»Ÿä¸€çš„LLMæ¥å£ï¼Œæ”¯æŒå¤šç§LLMæ¨¡å‹

import logging
from typing import Dict, Any, Callable, List
from langchain_core.messages import HumanMessage

# å¯¼å…¥LLMåŒ…è£…å™¨
from llm.deepseek_wrapper import DeepSeekLLM
from llm.qwen_llm import QwenLLM

# å…¨å±€LLMå®ä¾‹
_deepseek_llm = None
_qwen_llm = None

def get_deepseek_llm() -> DeepSeekLLM:
    global _deepseek_llm
    if _deepseek_llm is None:
        _deepseek_llm = DeepSeekLLM()
    return _deepseek_llm

def get_qwen_llm() -> QwenLLM:
    global _qwen_llm
    if _qwen_llm is None:
        _qwen_llm = QwenLLM()
    return _qwen_llm

def _call_to_str(call_fn: Callable[[str], Any], prompt: str) -> str:
    """ç»Ÿä¸€æŠŠæ¨¡å‹è¾“å‡ºè½¬æˆå­—ç¬¦ä¸²ï¼Œé¿å…ä¸Šæ¸¸ç±»å‹ä¸ä¸€è‡´"""
    out = call_fn(prompt)
    return out if isinstance(out, str) else str(out)

# === ç”Ÿæˆé“¾è·¯å…±ç”¨ï¼šè¿”å›ã€çº¯å­—ç¬¦ä¸²ã€‘ ===
def chat_with_llm(prompt: str) -> str:
    """
    ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼ˆé»˜è®¤ä½¿ç”¨åƒé—®LLMï¼‰
    è¿”å›ï¼šçº¯å­—ç¬¦ä¸²
    """
    try:
        qwen = get_qwen_llm()
        return _call_to_str(lambda p: qwen._call([HumanMessage(content=p)]), prompt)
    except Exception as e:
        logging.error("âŒ åƒé—®LLMè°ƒç”¨å¤±è´¥ï¼š%s", e)

        # å…œåº•é‡è¯• DeepSeek
        try:
            deepseek = get_deepseek_llm()
            resp = _call_to_str(lambda p: deepseek._call([HumanMessage(content=p)]), prompt)
            logging.info("âœ… ä½¿ç”¨ DeepSeek ä½œä¸ºå¤‡ç”¨æˆåŠŸï¼Œé•¿åº¦=%d", len(resp))
            return resp
        except Exception as backup_e:
            logging.error("âŒ å¤‡ç”¨ DeepSeek ä¹Ÿå¤±è´¥ï¼š%s", backup_e)
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"

def chat_with_llm_messages(messages: List[Dict[str, str]]) -> str:
    """
    ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨æ ¼å¼è°ƒç”¨LLMï¼ˆæ”¯æŒsystem + å†å²å¯¹è¯ + å½“å‰è¾“å…¥ï¼‰
    è¿”å›ï¼šçº¯å­—ç¬¦ä¸²
    """
    try:
        qwen = get_qwen_llm()
        # å°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºLangChainæ¶ˆæ¯æ ¼å¼
        langchain_messages = []
        for msg in messages:
            if msg["role"] == "system":
                from langchain_core.messages import SystemMessage
                langchain_messages.append(SystemMessage(content=msg["content"]))
            elif msg["role"] == "user":
                from langchain_core.messages import HumanMessage
                langchain_messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                from langchain_core.messages import AIMessage
                langchain_messages.append(AIMessage(content=msg["content"]))
        
        # æ‰“å°æœ€ç»ˆè¾“å…¥åˆ°LLM APIçš„åŸå§‹JSONæ•°æ®
        logging.info("=" * 80)
        logging.info("ğŸš€ æœ€ç»ˆè¾“å…¥åˆ°LLM APIçš„åŸå§‹JSONæ•°æ®")
        logging.info("=" * 80)
        
        # å°†LangChainæ¶ˆæ¯è½¬æ¢å›JSONæ ¼å¼
        import json
        json_messages = []
        for msg in langchain_messages:
            role = msg.__class__.__name__.replace("Message", "").lower()
            json_messages.append({
                "role": role,
                "content": msg.content
            })
        
        # æ‰“å°å®Œæ•´çš„JSONæ•°æ®
        logging.info(json.dumps(json_messages, ensure_ascii=False, indent=2))
        logging.info("=" * 80)
        
        return _call_to_str(lambda msgs: qwen._call(msgs), langchain_messages)
    except Exception as e:
        logging.error("âŒ åƒé—®LLMæ¶ˆæ¯åˆ—è¡¨è°ƒç”¨å¤±è´¥ï¼š%s", e)
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"

# === æ—¥è®°æ¨¡å—ç”¨ï¼šä¿æŒã€dictã€‘è¿”å›ï¼Œå…¼å®¹åŸæœ‰è°ƒç”¨ ===
def chat_with_qwen_llm(prompt: str) -> Dict[str, Any]:
    """
    åƒé—®LLMè°ƒç”¨æ¥å£ï¼ˆè¿”å› dictï¼ŒåŒ…å« answer å­—æ®µï¼‰
    """
    try:
        qwen = get_qwen_llm()
        resp = _call_to_str(lambda p: qwen._call([HumanMessage(content=p)]), prompt)
        return {"answer": resp}
    except Exception as e:
        logging.error("âŒ åƒé—®LLMè°ƒç”¨å¤±è´¥ï¼š%s", e)
        return {"answer": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"}

def chat_with_deepseek_llm(prompt: str) -> str:
    """
    DeepSeek LLMè°ƒç”¨æ¥å£ï¼ˆè¿”å›çº¯å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿é€šç”¨ï¼‰
    """
    try:
        deepseek = get_deepseek_llm()
        return _call_to_str(lambda p: deepseek._call([HumanMessage(content=p)]), prompt)
    except Exception as e:
        logging.error("âŒ DeepSeek LLMè°ƒç”¨å¤±è´¥ï¼š%s", e)
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"