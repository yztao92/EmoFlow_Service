# rag/rag_chain.py

from rag.prompts import RAG_PROMPT
from rag.retriever import retriever
from llm.chat import chat_with_llm

def run_rag_chain(query: str) -> str:
    # Step 1: æ£€ç´¢æ–‡æ¡£
    docs = retriever.get_relevant_documents(query)

    print("\nğŸ§  [è°ƒè¯•] æ£€ç´¢åˆ°æ–‡æ¡£å¦‚ä¸‹ï¼š")
    for i, doc in enumerate(docs):
        print(f"â€”â€” æ–‡æ¡£æ®µ {i+1} â€”â€”")
        print(doc.page_content[:200])  # æ˜¾ç¤ºå‰200å­—

    # Step 2: æ„é€  Prompt
    context = "\n\n".join([doc.page_content for doc in docs])
    prompt = RAG_PROMPT.format(context=context, question=query)

    # Step 3: è°ƒç”¨ LLM
    response = chat_with_llm(prompt)
    return response