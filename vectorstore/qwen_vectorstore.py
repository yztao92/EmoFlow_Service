# File: vectorstore/qwen_vectorstore.py
# åŠŸèƒ½ï¼šä½¿ç”¨åƒé—®text-embedding-v4æ¨¡å‹çš„å‘é‡åº“æ£€ç´¢ç³»ç»Ÿ
# å®ç°ï¼šåŠ è½½FAISSå‘é‡åº“ + SQLiteå…ƒæ•°æ®åº“ï¼Œæä¾›æ£€ç´¢æ¥å£

import faiss
import sqlite3
import numpy as np
import logging
from typing import List, Dict, Any, Tuple
import os

class QwenVectorStore:
    """
    åƒé—®å‘é‡åº“æ£€ç´¢å™¨
    åŠŸèƒ½ï¼šåŠ è½½FAISSå‘é‡åº“å’ŒSQLiteå…ƒæ•°æ®åº“ï¼Œæä¾›ç›¸ä¼¼åº¦æ£€ç´¢
    """
    
    def __init__(self, faiss_path: str, metadata_path: str):
        """
        åˆå§‹åŒ–å‘é‡åº“æ£€ç´¢å™¨
        
        å‚æ•°ï¼š
            faiss_path (str): FAISSå‘é‡åº“æ–‡ä»¶è·¯å¾„
            metadata_path (str): SQLiteå…ƒæ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.faiss_path = faiss_path
        self.metadata_path = metadata_path
        self.index = None
        self.embedding_model = None
        self.metadata_conn = None
        
        # åŠ è½½å‘é‡åº“å’Œå…ƒæ•°æ®åº“
        self._load_faiss_index()
        self._load_metadata_db()
        
    def _load_faiss_index(self):
        """åŠ è½½FAISSå‘é‡åº“"""
        try:
            if not os.path.exists(self.faiss_path):
                raise FileNotFoundError(f"FAISSå‘é‡åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.faiss_path}")
            
            self.index = faiss.read_index(self.faiss_path)
            # logging.info(f"âœ… FAISSå‘é‡åº“åŠ è½½æˆåŠŸ: {self.faiss_path}")
            # logging.info(f"ğŸ“Š å‘é‡åº“ä¿¡æ¯: {self.index.ntotal} ä¸ªå‘é‡, ç»´åº¦: {self.index.d}")
            
        except Exception as e:
            logging.error(f"âŒ FAISSå‘é‡åº“åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _load_metadata_db(self):
        """åŠ è½½SQLiteå…ƒæ•°æ®åº“"""
        try:
            if not os.path.exists(self.metadata_path):
                raise FileNotFoundError(f"å…ƒæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.metadata_path}")
            
            self.metadata_conn = sqlite3.connect(self.metadata_path)
            # æµ‹è¯•è¿æ¥
            cursor = self.metadata_conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM metadata")
            count = cursor.fetchone()[0]
            # logging.info(f"âœ… å…ƒæ•°æ®åº“åŠ è½½æˆåŠŸ: {self.metadata_path}")
            # logging.info(f"ğŸ“Š å…ƒæ•°æ®è®°å½•æ•°: {count}")
            
        except Exception as e:
            logging.error(f"âŒ å…ƒæ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
            raise
    
    def set_embedding_model(self, embedding_model):
        """
        è®¾ç½®embeddingæ¨¡å‹
        
        å‚æ•°ï¼š
            embedding_model: åƒé—®embeddingæ¨¡å‹å®ä¾‹
        """
        self.embedding_model = embedding_model
        # logging.info("âœ… Embeddingæ¨¡å‹è®¾ç½®æˆåŠŸ")
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æ£€ç´¢
        
        å‚æ•°ï¼š
            query (str): æŸ¥è¯¢æ–‡æœ¬
            k (int): è¿”å›ç»“æœæ•°é‡
        
        è¿”å›ï¼š
            List[Dict[str, Any]]: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦å’Œå…ƒæ•°æ®
        """
        if self.embedding_model is None:
            raise ValueError("Embeddingæ¨¡å‹æœªè®¾ç½®")
        
        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = self.embedding_model.embed_query(query)
        query_vector = np.array(query_vector).reshape(1, -1).astype('float32')
        
        # 2. FAISSæ£€ç´¢ï¼ˆä½¿ç”¨IndexIDMapï¼Œç›´æ¥è¿”å›IDï¼‰
        distances, ids = self.index.search(query_vector, k)
        
        # 3. è·å–å…ƒæ•°æ®
        results = []
        cursor = self.metadata_conn.cursor()
        
        for distance, doc_id in zip(distances[0], ids[0]):
            if doc_id == -1:  # FAISSè¿”å›-1è¡¨ç¤ºæ— æ•ˆç´¢å¼•
                continue
                
            # æŸ¥è¯¢å…ƒæ•°æ®ï¼ˆä½¿ç”¨åŸå§‹IDï¼‰
            cursor.execute("""
                SELECT id, url, title, question, answer_text, answer_summary, 
                       key_point, suggestion, topic, source, embedding_text
                FROM metadata WHERE id = ?
            """, (str(int(doc_id)),))  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ID
            
            row = cursor.fetchone()
            if row:
                # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆ1 - è·ç¦»ï¼‰
                similarity = 1.0 - float(distance)
                
                metadata = {
                    'id': row[0],
                    'url': row[1],
                    'title': row[2],
                    'question': row[3],
                    'answer_text': row[4],
                    'answer_summary': row[5],
                    'key_point': row[6],
                    'suggestion': row[7],
                    'topic': row[8],
                    'source': row[9],
                    'embedding_text': row[10],
                    'similarity': similarity,
                    'distance': float(distance)
                }
                results.append(metadata)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x['similarity'], reverse=True)
        
        # logging.info(f"ğŸ” æ£€ç´¢å®Œæˆ: æŸ¥è¯¢='{query[:50]}...', è¿”å› {len(results)} ä¸ªç»“æœ")
        # for i, result in enumerate(results[:3]):  # åªè®°å½•å‰3ä¸ªç»“æœ
        #     logging.info(f"  {i+1}. ç›¸ä¼¼åº¦ {result['similarity']:.3f} - {result['title'][:50]}...")
        
        return results
    
    def get_metadata_by_id(self, doc_id: str) -> Dict[str, Any]:
        """
        æ ¹æ®æ–‡æ¡£IDè·å–å…ƒæ•°æ®
        
        å‚æ•°ï¼š
            doc_id (str): æ–‡æ¡£ID
        
        è¿”å›ï¼š
            Dict[str, Any]: å…ƒæ•°æ®å­—å…¸
        """
        cursor = self.metadata_conn.cursor()
        cursor.execute("""
            SELECT id, url, title, question, answer_text, answer_summary, 
                   key_point, suggestion, topic, source, embedding_text
            FROM metadata WHERE id = ?
        """, (doc_id,))
        
        row = cursor.fetchone()
        if row:
            return {
                'id': row[0],
                'url': row[1],
                'title': row[2],
                'question': row[3],
                'answer_text': row[4],
                'answer_summary': row[5],
                'key_point': row[6],
                'suggestion': row[7],
                'topic': row[8],
                'source': row[9],
                'embedding_text': row[10]
            }
        return None
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.metadata_conn:
            self.metadata_conn.close()
            # logging.info("âœ… å…ƒæ•°æ®åº“è¿æ¥å·²å…³é—­")

# å…¨å±€å‘é‡åº“å®ä¾‹
_qwen_vectorstore = None

def get_qwen_vectorstore() -> QwenVectorStore:
    """
    è·å–åƒé—®å‘é‡åº“å®ä¾‹ï¼ˆæ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°å®ä¾‹ï¼Œé¿å…çº¿ç¨‹é—®é¢˜ï¼‰
    
    è¿”å›ï¼š
        QwenVectorStore: å‘é‡åº“å®ä¾‹
    """
    faiss_path = "dataset/faiss_index.bin"
    metadata_path = "dataset/metadata.db"
    vectorstore = QwenVectorStore(faiss_path, metadata_path)
    
    # åŠ¨æ€è®¾ç½®embeddingæ¨¡å‹
    try:
        from llm.qwen_embedding_factory import get_qwen_embedding_model
        embedding_model = get_qwen_embedding_model()
        vectorstore.set_embedding_model(embedding_model)
    except Exception as e:
        logging.warning(f"âš ï¸ åŠ¨æ€è®¾ç½®embeddingæ¨¡å‹å¤±è´¥: {e}")
    
    return vectorstore

def set_qwen_embedding_model(embedding_model):
    """
    è®¾ç½®åƒé—®embeddingæ¨¡å‹
    
    å‚æ•°ï¼š
        embedding_model: åƒé—®embeddingæ¨¡å‹å®ä¾‹
    """
    vectorstore = get_qwen_vectorstore()
    vectorstore.set_embedding_model(embedding_model) 